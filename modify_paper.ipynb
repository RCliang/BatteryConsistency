{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import enum\n",
    "import argparse\n",
    "import polars as pl\n",
    "# Visualization related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Deep learning related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.hub import download_url_to_file\n",
    "from torch.utils.data import Dataset\n",
    "# Data manipulation related imports\n",
    "# from torchtext.data import Dataset, BucketIterator, Field, Example\n",
    "# import spacy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatteryData(Dataset):\n",
    "    def __init__(self, data_dir, processor, final_cols) -> None:\n",
    "        super().__init__()\n",
    "        self.processor = processor\n",
    "        # self.ares = self.load_data(data_dir)\n",
    "        data = pl.read_parquet(data_dir)\n",
    "        self.ares, self.ares_y = self.processor.process_data(data.select(final_cols))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ares.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.ares\n",
    "        Y = self.ares_y\n",
    "        return X[index], Y[index]\n",
    "    \n",
    "    def load_data(self, data_dir):\n",
    "        path_list = os.listdir(data_dir)\n",
    "        data = []\n",
    "        for item in os.listdir(data_dir):\n",
    "            data.append(self.processor.process_data(pl.read_parquet(os.path.join(data_dir,item))))\n",
    "        res = pl.concat(data)\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_data_info(data_dir):\n",
    "        data_info={}\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"file: {file}\")\n",
    "                data = pl.read_parquet(file_path)\n",
    "                yield data\n",
    "class processor:\n",
    "    def __init__(self, groups, seq_len, step_size) -> None:\n",
    "        self.groups = groups\n",
    "        self.seq_len = seq_len\n",
    "        self.step_size = step_size\n",
    "    \n",
    "    def process_data(self, data:pl.DataFrame):\n",
    "        final_res = []\n",
    "        final_y = []\n",
    "        for item in data.groupby(self.groups):\n",
    "            data_tmp = item[1]\n",
    "            data_tmp = data_tmp.drop('cycle')\n",
    "            l = data_tmp.shape[0]\n",
    "            if l < self.seq_len:\n",
    "                continue\n",
    "            # steps = int((l-self.seq_len)//self.step_size+1)\n",
    "            steps = int(l-self.seq_len*2+self.step_size)\n",
    "            for i in range(steps+1):\n",
    "                X_tensor = torch.from_numpy(data_tmp[i:i+self.seq_len].to_numpy())\n",
    "                y_tensor = torch.from_numpy(data_tmp[i+self.step_size:i+self.step_size+self.seq_len].select('D135_diff').to_numpy())\n",
    "                final_res.append(X_tensor)\n",
    "                final_y.append(y_tensor)\n",
    "            # X_tensor = torch.from_numpy(data_tmp[-self.seq_len-self.step_size:-self.step_size].to_numpy())\n",
    "            # if X_tensor.shape[0] < 10: continue\n",
    "            # y_tensor = torch.from_numpy(data_tmp[-self.seq_len:].select('D135_diff').to_numpy())\n",
    "            # final_res.append(X_tensor)\n",
    "            # final_y.append(y_tensor)\n",
    "        ares = torch.cat(final_res)\n",
    "        ares = ares.reshape((-1, self.seq_len, data_tmp.shape[1]))\n",
    "        ares_y = torch.cat(final_y)\n",
    "        ares_y = ares_y.reshape((-1, self.seq_len, 1))\n",
    "        return ares, ares_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, model_dimension):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=model_dimension,\n",
    "                out_features=256,\n",
    "                bias=True\n",
    "            ),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifica = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc1 = F.dropout(self.hidden1(x))\n",
    "        fc2 = F.dropout(self.hidden2(fc1))\n",
    "        output = self.classifica(fc2)\n",
    "        return F.log_softmax(output)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, model_dimension, dropout_probability, expected_max_sequence_length=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        position_id = torch.arange(0, expected_max_sequence_length).unsqueeze(1)\n",
    "        frequencies = torch.pow(10000., -torch.arange(0, model_dimension, 2, dtype=torch.float) / model_dimension)\n",
    "\n",
    "        # Checkout playground.py for visualization of how these look like (it's super simple don't get scared)\n",
    "        positional_encodings_table = torch.zeros(expected_max_sequence_length, model_dimension)\n",
    "        positional_encodings_table[:, 0::2] = torch.sin(position_id * frequencies)  # sine on even positions\n",
    "        positional_encodings_table[:, 1::2] = torch.cos(position_id * frequencies)  # cosine on odd positions\n",
    "\n",
    "        self.register_buffer('positional_encodings_table', positional_encodings_table)\n",
    "\n",
    "    def forward(self, embeddings_batch):\n",
    "        assert embeddings_batch.ndim == 3 and embeddings_batch.shape[-1] == self.positional_encodings_table.shape[1], \\\n",
    "            f'Expected (batch size, max token sequence length, model dimension) got {embeddings_batch.shape}'\n",
    "\n",
    "        positional_encodings = self.positional_encodings_table[:embeddings_batch.shape[1]]\n",
    "        return self.dropout(embeddings_batch + positional_encodings)\n",
    "\n",
    "class DTN_model(nn.Module):\n",
    "    def __init__(self, model_dimension, number_of_heads, number_of_layers,d_hid, dropout_probability, number_of_var,\n",
    "                 hidden_dimension_list,in_channel, out_channel, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        # Periodic Embeddings\n",
    "        # two different encoders and decoders\n",
    "        EncoderLayer = nn.TransformerEncoderLayer(d_model=model_dimension,\n",
    "                                                  nhead=number_of_heads,dim_feedforward=d_hid, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(EncoderLayer, num_layers=number_of_layers)\n",
    "        self.fw_embedding = nn.Linear(number_of_var, model_dimension)\n",
    "        self.bw_embedding = nn.Linear(number_of_var, model_dimension)\n",
    "        self.pos_embedding = PositionalEncoding(model_dimension, dropout_probability)\n",
    "\n",
    "        self.decoder = nn.Conv1d(in_channel, out_channel, kernel_size, stride)\n",
    "        self.mlp = nn.ModuleList([nn.Sequential(nn.Linear(int((model_dimension - kernel_size)/stride+1),hidden_dimension_list[0]),nn.ReLU())]\n",
    "                                 +[nn.Sequential(nn.Linear(hidden_dimension_list[i-1],hidden_dimension_list[i]),nn.ReLU()) for i in range(1,len(hidden_dimension_list))])\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        # I tested both PyTorch's default initialization and this, and xavier has tremendous impact! I didn't expect\n",
    "        # that the model's perf, with normalization layers, is so dependent on the choice of weight initialization.\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        tmp=tokens[:,:,0].squeeze()\n",
    "        tmp = tmp.reshape((-1,tokens.shape[1]))\n",
    "        key_padding_mask = torch.zeros(tmp.size())\n",
    "        key_padding_mask[tmp == 0] = -torch.inf\n",
    "        return key_padding_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_bw_mask(bw_tensor):\n",
    "        bw_mask = nn.Transformer.generate_square_subsequent_mask(bw_tensor.size()[-2])\n",
    "        return bw_mask\n",
    "    \n",
    "    def encode(self, input, src_mask):\n",
    "        input_embeddings = self.fw_embedding(input)\n",
    "        input_embeddings = self.pos_embedding(input_embeddings)\n",
    "        input_repr = self.encoder(input_embeddings, src_key_padding_mask=src_mask)\n",
    "        return input_repr\n",
    "    \n",
    "    def decode(self, input):\n",
    "        return bw_repr\n",
    "        \n",
    "    def forward(self, input, src_mask):\n",
    "        input_repr = self.encode(input, src_mask)\n",
    "        # decode_repr = self.decoder(input_repr.permute([0,2,1])).permute([0,2,1])\n",
    "        decode_repr = self.decoder(input_repr)\n",
    "        for m in self.mlp:\n",
    "            decode_repr = m(decode_repr)\n",
    "        # for m in self.mlp:\n",
    "        #     input_repr = m(input_repr)\n",
    "        # pred = F.log_softmax(input_repr,dim=1)\n",
    "        return decode_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data_dir, model, loss_fn, optimizer, final_cols):\n",
    "    size = 0\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    batch = 0\n",
    "    for file in [x for x in os.listdir(data_dir) if 'parquet' in x]:\n",
    "        print(os.path.join(data_dir,file))\n",
    "        # key = file.split('_')[0]\n",
    "        battery_data = BatteryData(os.path.join(data_dir,file), dataProcess, final_cols)\n",
    "        dataloader = DataLoader(dataset=battery_data,batch_size=2,shuffle=True,num_workers=0)\n",
    "        size += len(dataloader.dataset)\n",
    "        # loss_file[key] = []\n",
    "        tmp_loss=[]\n",
    "        for _batch, (X, y) in enumerate(dataloader):\n",
    "            pred = model(X.float().cuda(), model.get_key_padding_mask(X.cuda()).float().cuda())\n",
    "\n",
    "            loss = loss_fn(pred.reshape((X.shape[0],X.shape[1],-1)).float(), y.float().cuda())\n",
    "            train_loss+=loss.item()\n",
    "            tmp_loss.append(loss.item())\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            batch+=1\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "                # loss_train.append(sum(tmp_loss)/len(tmp_loss))\n",
    "                tmp_loss=[]\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dimension = 512\n",
    "number_of_heads = 4\n",
    "number_of_var = 114\n",
    "number_of_layers = 3\n",
    "dropout_probability = 0.4\n",
    "hidden_dimension_list = [512,64,16,1]\n",
    "d_hid = 512\n",
    "in_channel = 10\n",
    "out_channel = 10\n",
    "kernel_size = 10\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcess = processor(['cycle'], 10, 5)\n",
    "data_dir = 'processed_data/normal_sample/charge_data'\n",
    "file = 'processed_data/normal_sample/charge_data/D105_4_5.parquet'\n",
    "final_cols = [f\"D135_{i}_dv\" for i in range(1,113)]+['D135_diff','D135_std_max']+['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_data = BatteryData(os.path.join(data_dir,file), dataProcess, final_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
